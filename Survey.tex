\documentclass[11pt]{IEEEtran}

\usepackage{cite}
\usepackage{graphicx}
\graphicspath{{img/}}
\usepackage{hyperref}
\usepackage[linesnumbered,lined,boxed,commentsnumbered]{algorithm2e}



\begin{document}

% Subject : Symbolic executions technique for finding bugs %
\title{A Survey of\\Symbolic Executions Techniques} % NB: I removed the "for finding bugs" because "bug" is not well-defined and we can clearly state in the introduction why we use symbolic execution.
\author{Hallet Adrien \and Sens Loan}
\date{\today}
\maketitle

  \section*{Abstract}
    % Describe paper's goals and content

  \section{Introduction}
    \subsection{A definition}
      % I tried to explain what is symbolic execution in simple concepts of software engineering
      The first occurences of symbolic execution described the then-new method as a middle ground~\cite{newapproach} between the two most-used method of its time: \emph{program testing} and \emph{program provign}.
      Nowadays, symbolic execution is both described as (part of) the core of many modern techniques to software testing\cite{chopper:icse18} and an effective way to create tests suites with extensive coverage.\cite{threedecadeslater}
    \subsection{The concept}
      The idea behind symbolic execution is to test an algorithm with \emph{symbolic values} rather than concrete values. So instead of using unit testing where a variable is set to a (usually random) value, the symbolic execution maintains a formula that contains all the possible values for the code to reach a particular point in the program. This formula is updated every time the program reaches a branching point. In figure~\ref{fig:symbolicsimple}, we show an example from~\cite{visserWillemCorina} of a symbolic execution. Notice how it produces constraints over the variables to explore the algorithm's branching tree.
      \begin{figure}
        \includegraphics[width=0.5\textwidth]{symbolicsimple}
        \caption{Swapping two integers and its symbolic execution tree}
        \label{fig:symbolicsimple}
      \end{figure}
    % What is symbolic execution and why do we do this survey

  \section{History}
    We find the first papers on symbolic execution around 1975~\cite{newapproach}. Early methods proposed simple structures to hold conditions with a SAT-solver, the support of simple data types and were focused on algorithm testing (instead of large programs). While papers continue to grow on the subject, it really is around 2005 that symbolic execution really becomes a large thing with more and more frameworks and tools for software verification. The last ten years have seen more papers on the subject\footnote{Data from Google Scholar} (around 200.000) than the three decades following its introduction (half that much). Among the supporters of the method, we can identify two clear research poles, China~\cite{Hardware, memorytablemodel, CHEN2018118} and the United States of America, with an heavy participation of Microsoft~\cite{bouncer-securing-software-by-blocking-bad-input} which was pooling heavy resources in software and OS reliability, and the NASA~\cite{neurosymbolicexecution, DirectedIncrementalSymExe, visserWillemCorina}.

  \section{Method}
    % Begin with anything general to say (if any) then detail methods, could also be useful to compare them (if possible) and/or to say when/why a particular method is being used instead of another.
    \subsection{Useful concepts}
      Algorithms can be modeled as graphs where nodes are basic blocks (\emph{i.e.: a part, one or multiple instructions with a single entry and exit point}) and edges are the branches (issued from conditional statements). Def-use pairs use the same concept, although they base their graph on the \emph{definition} and \emph{usage} of a variable. With the \emph{branches} and \emph{def-use pairs}, we can model an algorithm's behavior to follow the values of its variables and determine the \emph{execution path}.
    \subsection{Basis}
      \label{sub:basis}
      Symbolic execution works on those concepts by updating an internal list of symbols. The execution generates a new symbol for each introduced variable in an algorithm\cite{newapproach}. The symbolic execution runs over the algorithm's statements and builds the symbolic values when it encounters a branching point. The symbolically executed algorithm creates a \emph{state}\cite{visserWillemCorina} containing the symbolics values, a counter identifying the next line to be executed and a \emph{path condition}. This path condition is a simple boolean formula over the symbols, it creates a constraint for the algorithm to reach the current state of the program (this also allows to check for unreachable paths in programs~\cite{InfeasiblePathsEliminationWithSymbolicExecTechniques}). The path condition allows to recreate the execution up to its state. The states are stored in a \emph{symbolic execution tree} with the states as nodes and the transitions as edges (see figure~\ref{fig:symbolicsimple}).
    \subsection{Problems}
      \label{sec:problems}
      \subsubsection{State-Space Explosion}
        \label{subsec:state-space-explosion}
        Symbolic Execution cannot be that perfect and hosts its bundle of problems that reduce either the confidence in or the performances of the concept. We have seen symbolic execution tree in~\ref{sub:basis}. Small algorithms can use such methods but actual programs need to be tested in \emph{integration}. In large environments, the tree's branching factor will produce too many nodes (\emph{state-space explosion}) for the performances to stay relevant, sometimes creating infinite loops in the graph~\cite{forwardSymbolicExecution}. Reducing the state space or pruning them is not enough. To improve the performances, we can depth-first-search the graph but it does not prevent infinite loops until we add a max depth (as KLEE or EXE do). %TODO: Ref the tools when (if) we cite them.
        Pruning heuristics (\emph{e.g.:def-use pairs distance}) can be used to reduce the tree's branching factor, we may randomly select a path (emph{i.e: the path condition}), weighting the shallowest nodes to avoid dead-loops. The random technique is exploited by a lot of \emph{fuzzing techniques}~\cite{CHEN2018118} which uses the injection of random values to detect program's faults. Another solution lies in the \emph{concolic execution} (see~\ref{subsec:concolicExecution}).

      \subsubsection{Modeling the memory}
        Another technical difficulty lies in the \emph{memory model}. As said before, a symbol $\alpha$ represents a variable \texttt{a} with a value. In the programming world, it means there is a pointer \texttt{a*} that stores the address to an allocated memory block. The initial approach~\cite{newapproach} proposed a \emph{fully symbolic memory}. The symbols are stored in plain states holding their path condition with either a duplication of the states depending on their memory status called \emph{state forking} where every possible execution is forked from the main branch (\emph{e.g.: accessing an array of size 10 with a variable $i$ that depends on the context will fork 10 states from the main memory state, each one with $i$ from 0 to 9}). Fully symbolic memory is therfore slowed by an increased \emph{state-space explosion}. To reduce memory usage, some tools may represent an artificial memory space~\cite{5635129}, which reduces the size of the general space by allowing more memory to each path condition, although doing so will void some execution paths, leaving potential bugs out of the symbolic execution. An italian approach~\cite{memorymodelpointers} proposes the use of a \emph{symbolic} adress which holds the condition to which address the variable points to, which drastically reduces the amount of memory states.

        Instead of fully modeling the memory, there also is the \emph{abstract symbol table}~\cite{memorytablemodel} which records tuples [variable, address, symbolic value]. This method has the advantage of supporting complex data types (some fully memory models cannot express structures) and memory aliasing (instead of creating a new variable copied from another in older methods).
  \section{Variants}
    % I split the section because it was too heavy for my liking and I think we can better state the base and what challenges it produces, then look at how we can solve them with variants. It also allows the reader to just skip the variants in the future if he just wants to know about the method.
    \subsection{Concolic execution}
    \label{subsec:concolicExecution}
    	\emph{Concolic}, portmanteau from \emph{concrete} and \emph{symbolic}, the idea of this testing method is to mix symbolic execution alongside concrete ones.\\

    	\subsubsection*{Concolic execution approaches}
    		This technique concept was first introduced on 2005 \cite{godefroid2005dart} (more details on section \ref{subsec:DART}). % The name used wasn't "Concolic" yet but the concept idea was the same
    	Since then the idea was further extended and combined with other testing techniques.\\

    	However, the general principle has been explored with different angles.

    		\subsubsection{Dynamic Symbolic Execution}
    		\label{subsec:dynamicSymbolicExec}
    			\emph{Dynamic Symbolic Execution} (DSE) also kwown as \emph{dynamic test generation} \cite{godefroid2005dart} is a popular approach of concolic execution. Its main feature is to have the symbolic execution driven by  the concrete execution.\\

    			For this method, we will first need to add a new store in order to save the concrete execution information.\\
    			The first step involves choosing an arbitrary value as input for our parameters. Then it executes the program concretely and symbolically at the same time updating both stores and the path constraints. When the concrete execution is directed on a certain branch, the symbolic execution follows it and the constraint is appended the the set of path constraints.\\
    			In order to explore different paths, we generate new control flows by negating one or more constraints. We can repeat this process as many time as we want to achieve the intended coverage.\\

    			Notice that it exists different strategies on the choice of the branch to negate, this crucial heuristic choice depends of the tool.\\

    		\subsubsection*{Downside : Imperfect symbolic execution}
    			\begin{itemize} % description layout act strangely here
    				\item \emph{False Negative} : Missed path. For example, when another function from the one tested is not symbolically tracked but its result is needed to explore a particular path.
    				\item \emph{Path Divergence} : In some situations the engine can't guess that no input can provoke an error. In other word, whenever an actual execution path does not match the program path predicted by symbolic execution for a given input vector. For example, assert on a negative value of an absolute value due to the untracked side effect of the \texttt{abs()} function.\\
    				According to \cite{Godefroid2008AutomatedWF} they calculated a divergence rates of over 60 \%
    			\end{itemize}

    	\subsubsection{Selective Symbolic Execution}
    	\label{subsec:selectiveSymbolicExec}
    		This approach is based on the observation that often only some families of paths are meaningful\cite{chipounov2012s2e}. We focus the exploration on some designated interesting component of the software while not caring about the others. It offers an illusion of symbolically executing a full software stack, while actually executing symbolically only select components.\\

    		The selective symbolic execution switch back and forth between symbolic and concrete execution, depending if the current component is relevant or not. When it is symbolic the tree may expand in width and depth, on the other hand in a concrete execution it only grows in depth as only one branch is created (see Figure \ref{fig:selectiveSymbolicExample} ).
    		\begin{figure}
    			\centering
    			\includegraphics[scale=0.9]{selectiveSymbolicExecExample.png}
    			\label{fig:selectiveSymbolicExample}
    			\caption{Multipath/single-path execution: three different modules (left) and the resulting execution tree (right). Shaded areas represent the multipath (symbolic) execution domain, while the white areas are single-path. More details in section \ref{subsec:S2EExample}}
    		\end{figure}



  \section{Tools and languages}
  %TODO : autre outils potentiels : SAGE
  	Many tools exist for symbolic execution, \href{https://en.wikipedia.org/wiki/Symbolic_execution\#Tools}{Wikipedia} mention 22 of them. Another \href{https://github.com/ksluckow/awesome-symbolic-execution\#tools}{source} claiming to "curate a list of awesome symbolic execution resources including tools" mention 35 different tools spread over 10 different languages.\\ %TODO [Loan] : est-ce qu'on ajoute ça dans la biblio ?

    % Anything general to say bout the content (maybe explain the omnipresence of Microsoft in the market)
    % List tools and language, compare them if possible


    % Let DART be first as it is the first used tool to use concolic
    \subsection{\emph{DART} : Directed Automated Random Testing}
    \label{subsec:DART}
    	\emph{DART} is presented as a tool for automatically testing software using concolic testing method. It was introduced in 2005 making it the first the first tool to be created using concolic techniques and more specifically dynamic symbolic execution techniques (see section \ref{subsec:dynamicSymbolicExec}). \\

    	\subsubsection{Methodology}
	    	\emph{DART} combines three main techniques 	    	\cite{godefroid2005dart} in order to automate the process of testing for a particular software :
	    	\begin{enumerate}
	    		\item An automated extraction of the interface of a program with its external environment using static source-code parsing
	    		\item An automatic generation of a test driver for this interface that performs random testing to simulate the most general environment the program can operate in
	    		\item A dynamic analysis of how program behaves under random testing and automatic generation of new test inputs to direct systemically the execution along alternatives program paths
	    	\end{enumerate}

			\emph{DART} chooses the \emph{depth-first} strategy whenever it has to negate a branch.

	    \subsubsection{Example}
		    Let consider the following program :

		    \begin{algorithm}
		    	\SetKwFunction{Ffoo}{foo}
		    	\SetKwProg{Fn}{Function}{:}{}

		    	\Fn{\Ffoo{int x, int y}}{
			    	\If{x != y} {
						\If {2 * x == x + 10} {
							ERROR\;
						}
			    	}
			    	\KwRet SUCCESS\;
		    	}

		    \end{algorithm}

	    	This function is defective as it may lead to an error statement for some value of $x$ and $y$.\\
	    	\emph{DART} start by guessing values for both $x$ and $y$ for instance $269167349$ and $889801541$. With this values the function return  successfully, during the execution two predicates were formed created by the \texttt{if} statements, in our case the path constraint at the end is : $\langle x_0 \neq y_0, 2 \times x_0 \neq x_0 + 10 \rangle$ with $x_0$ and $y_0$ both beings \emph{symbolic variables}.\\ %TODO : garder la convention de notation du survey
	    	While we maintain this predicates, all path will lead to the same end. So in order to force  the program through a potential different outcome we change one of the predicate and look at the result. If we negate the last predicate we have the following path constraint : $\langle x_0 \neq y_0, 2 \times x_0 = x_0 + 10 \rangle$ in which $x_0=10$ and $y_0=889801541$ is a solution. Using this values as inputs the program end up into the \texttt{ERROR} as wanted.

	    \subsubsection{Key strength/originality}
	    	One of the main strength of DART is that, on any compilable program, testing can be performed completely automatically. There is no need to write any additional harness code or test driver.\\
	    	During testing, DART detects standard errors such as program crashes, assertion violations, and non-termination.\\
	    	Due to its based on precised dynamic analysis, DART provides an interesting alternative to static analyzer. It is expected to be very good at the detection of some kind of bugs\footnote{Especially  interprocedural bugs and bugs that happen through library functions use} compare to a dynamic analyzers.\\
	    	Any errors founded by DART during the execution is sure to be sound.\\

	    	But DART has its own limitations, particularly the limited effectiveness of dynamic test generation to improve over random testing and the computational cost of running tests.
	    	
	\subsection{JDART}
		\emph{JDART} describes itself as a dynamic symbolic analysis framework for \emph{Java} \cite{jDart}.\\
		The main goal of the tool is to build a dynamic symbolic analysis tool that can be used to industrial scale complex software. Another important aspect was the main design guideline they wish to be modular and extensible.\\
		
		%TODO [Loan] : Si nécessaire, parler plus en profondeur des features de JDART "As mentioned, the key distinguishing feature of JDart is its modular architecture.The two main components of JDart are the Executor and the Explorer ."
		
		Looking at the \href{https://github.com/psycopaths/jdart}{repository of the project}, the project started around 2015. But it seems that it stagnates since 2017 based on last commits.
		% JDART parle de JCUTE dans la section 4 : "Several symbolic execution tools specifically target Java Bytecode programs. A number of them implement dynamic symbolic execution via Java Bytecode instrumentation. JCute [27], the first concolic execution engine for Java, uses Soot [30] for instrumentation, and uses lp_solve as a constraint solver. JCute is no longer maintained."
		
		%TODO : relation entre JDART et JPF : "Currently, JDart uses the software model checker Java PathFinder (JPF) for the execution of Java Bytecode programs." Mais on ne parle pas de JPF encore, donc ça ne serai pas pertinant 

	\subsection{S$^2$E}
    \label{subsec:S2E}
    	S$^2$E is a platform for writing tools that analyze the properties and behavior of software system. It comes as a modular library that gives virtual machines symbolic execution and program analysis capabilities.\cite{S2EWebSite} It uses selective symbolic execution concolic execution (see section  \ref{subsec:selectiveSymbolicExec}).


    	%TODO : mettre ça quelque part peut-être ? "S2E is built upon the KLEE symbolic execution engine and the QEMU virtual machine emulator."

    	\subsubsection{Methodology}
    		S$^2$E switch dynamically between symbolic and concrete execution. This transition is not trivial and must be treated separately.\\
    		Let \texttt{A} and \texttt{B} be function such as \texttt{A} calls \texttt{B}.\\
    		\subsubsection*{From concrete to symbolic and back}
    			\texttt{A} calls \texttt{B} with concrete arguments as we are still in a concrete execution. However \texttt{B} is symbolic, therefore it modify the arguments sends by \texttt{A} to make them symbolic. For instance \texttt{B(10)} become \texttt{B($\lambda$)}. In can additionally be set to some constraints, for example \texttt{B($\lambda < 15$)}.\\
    			After the transition occurs, S$^2$E executes \texttt{B} symbolically using the symbolic argument(s) and at the same time with the concrete argument(s).\\
    			Once the exploration of \texttt{B} is over, S$^2$E returns to \texttt{A} the concrete returned value of the concrete execution.\\
    			In this way, the execution of \texttt{A} is always consistent, meanwhile S$^2$E use the extra symbolic path in its analyzer plugin to check for possible issues.

    		\subsubsection*{From symbolic to concrete and back}
    			\texttt{A} calls \texttt{B} with symbolic arguments as we are still in a symbolic execution. However \texttt{B} is concrete, therefore it modify the arguments sends by \texttt{A} to make them concrete while still maintaining path constraints. For instance if we have the path constraint  $\langle \lambda < 5 \rangle$, we can choose -20 or 3 as a concrete value but not 5 or 42.\\
    			After this choice, \texttt{B} execute concretely then return symbolically back to \texttt{A} which resume symbolically.\\

    			Note that S$^2$E actually employs "lazy-concretization": It converts the value of $\lambda$ from symbolic to concrete on-demand, only when concretely running code is about to branch on a condition that depends on the value of $\lambda$. \\

    			It's important to mention that this transition may lead to the "overconstraining" problem, which impact both the soundness and completeness of the tool. The problem that may rises can be :
    			\begin{itemize}
    				\item Exclusion of paths due to the concretisation of the arguments
    				\item Exclusion of paths indirectly due to the the constrained return value
and side effects
    			\end{itemize}
    			%TODO : il y aurait une solution à ce problème en marquand les contraitnes comme "soft" ou quoi, à approfondir si on à le temps



    	\subsubsection{Example}
    	\label{subsec:S2EExample}
    		Let's use the figure \ref{fig:selectiveSymbolicExample} as a reference example, it describes an application \emph{app} using a library \emph{lib} on top of an OS \emph{kernel}. We are interested in testing the \emph{lib}, but not the \emph{app} nor the \emph{kernel}. Therefore only the \emph{lib} will be executed symbolically, the 2 others will be concrete.\\

    		\emph{app} call the function \emph{appFn} which itself calls a \emph{lib} function \emph{libFn}, which eventually invokes a system call \emph{sysFn}. After that \emph{sysFn} returns, \emph{libFn} does some extra execution and then eventually returns to \emph{appFn}. Once the execution crosses into the symbolic domain (gray shaded part) from the concrete domain (white part), the execution tree expands. After the executions returns again to the concrete domain, the execution tree no longer expand, it may still grows, but it does not add any new paths until the execution become symbolic domain again. A path may terminate prematurely, for example in case of hitting a crash bug.


    \subsection{EXE}
      Section~\ref{subsec:state-space-explosion} stated the memory problem. \textbf{EXE} is a tool (focused on C) that aims to reduce that with the use of concolic execution within the states, allowing to partially store the states and using the path condition to recreate the output if needed. The tool bases itself over the principle of \emph{EGT - Execution Generated Testing}~\cite{exe}, which is basically the classic approach to symbolic execution. The tool uses a constraint solver working on the path condition to prune the tested algorithm's branches (simply deleting unsatisfiable constraints, branches that cannot logically exist can be generated due to the symbolic value, this pruning removes them), then to solve the constraint to generate a set of test value. The tool also uses models to check code coverage, which is only optional.

      Although good for its time, EXE still suffers from the same problems and a new one; \emph{isolation}. The tool is isolated from the environment and any kind of interaction ruined the double execution of symbolic and concrete data. Interacting with a network, input, ... would result in the loss of the symbolic execution or would require a full model of the world to interact with (which ranges from difficult to impossible). Furthermore, the need for a model for sufficient coverage requires a realistic and complete model. Functions which return the same value for different outputs (\emph{e.g.: in Java, if you compare an object to another}) or worse; different values for the same input, would result in models that would not quite work with the tool. On top of that, the tool works assuming it has a good SAT-solver (and as we know, 3-SAT is np-complete) and available memory.

    \subsection{KLEE}
      This tool~\cite{klee} is a complete rework of EXE, also focused on C, by the same authors three years later (2008). While the basis were the same, KLEE managed to largely improve the execution time and space by keeping its advantages (\emph{exact memory representation}, constraint solving, high code coverage). To reduce the space bottleneck, KLEE stores the states concurrently, sharing them, allowing larger sets of states to be used by the same execution. It is important to note that KLEE does not mindlessly check each instruction. Sets of dangerous operations which can lead to failures rather than wrong outputs are determined. In the C-language context, it means memory accesses and allocation. %ToDo [adrien] : continue this

  \section{Conclusions}
    % What can we get from this paper in general
    % Could be pertinent to talk about a kind of "to go further" which could contain adjacent fields of research
    % Could be pertinent to talk about the future of symbolic execution, if there is any new technique being developed, ...


\pagebreak
\bibliography{bibliography}{}
\bibliographystyle{plain}
\end{document}
